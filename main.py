import feedparser
import os
import time
import re
import requests
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium_stealth import stealth

# --- Ø¨Ø±Ù…Ø¬Ø© ahmed si - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù…ØµÙ‚ÙˆÙ„Ø© (v37) ---

# ====== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆÙ‚Ø¹ - ØºÙŠÙ‘Ø± Ù‡Ù†Ø§ ÙÙ‚Ø· ======
SITE_NAME = "grandmabites"  # Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø¨Ø¯ÙˆÙ† .com
SITE_DOMAIN = f"{SITE_NAME}.com"
RSS_URL = f"https://{SITE_DOMAIN}/feed"

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
IMAGE_PATHS = [
    "/assets/images/",
    "/wp-content/uploads/",
    "/images/",
    "/media/",
    "/static/images/",
    "/content/images/",
    f"/{SITE_NAME}",
    "/recipes/images/",
]
# ==========================================

POSTED_LINKS_FILE = "posted_links.txt"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

def get_posted_links():
    if not os.path.exists(POSTED_LINKS_FILE): return set()
    with open(POSTED_LINKS_FILE, "r", encoding='utf-8') as f: return set(line.strip() for line in f)

def add_posted_link(link):
    with open(POSTED_LINKS_FILE, "a", encoding='utf-8') as f: f.write(link + "\n")

def get_next_post_to_publish():
    print(f"--- 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù‚Ø§Ù„Ø§Øª ÙÙŠ: {RSS_URL}")
    feed = feedparser.parse(RSS_URL)
    if not feed.entries: return None
    print(f"--- ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(feed.entries)} Ù…Ù‚Ø§Ù„Ø§Øª.")
    posted_links = get_posted_links()
    for entry in reversed(feed.entries):
        if entry.link not in posted_links:
            print(f">>> ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„: {entry.title}")
            return entry
    return None

def extract_image_url_from_entry(entry):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ ØµÙˆØ±Ø© Ù…Ù† RSS feed"""
    if hasattr(entry, 'media_content') and entry.media_content:
        for media in entry.media_content:
            if 'url' in media and media.get('medium') == 'image': return media['url']
    if hasattr(entry, 'enclosures') and entry.enclosures:
        for enclosure in entry.enclosures:
            if 'href' in enclosure and 'image' in enclosure.get('type', ''): return enclosure.href
    content_html = ""
    if 'content' in entry and entry.content: content_html = entry.content[0].value
    else: content_html = entry.summary
    match = re.search(r'<img[^>]+src="([^">]+)"', content_html)
    if match: return match.group(1)
    return None

def is_valid_article_image(url):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© ØµØ§Ù„Ø­Ø© Ù„Ù„Ù…Ù‚Ø§Ù„"""
    small_sizes = ['16', '32', '48', '64', '96', '128', '150', '160']
    for size in small_sizes:
        if f'width={size}' in url or f'w={size}' in url or f'-{size}x' in url or f'_{size}x' in url:
            return False
    
    exclude_keywords = [
        'avatar', 'author', 'profile', 'logo', 'icon', 
        'thumbnail', 'thumb', 'placeholder', 'blank',
        'advertising', 'banner', 'badge', 'button'
    ]
    url_lower = url.lower()
    if any(keyword in url_lower for keyword in exclude_keywords):
        return False
    
    if any(x in url_lower for x in ['pixel', 'tracking', 'analytics', '.gif']):
        return False
    
    valid_extensions = ['.jpg', '.jpeg', '.png', '.webp']
    has_valid_extension = any(ext in url_lower for ext in valid_extensions)
    
    return has_valid_extension

def scrape_article_images_with_alt(article_url):
    """ÙƒØ´Ø· Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù†ØµÙˆØµ alt Ù…Ù† Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù‚Ø§Ù„"""
    print(f"--- ğŸ” ÙƒØ´Ø· ØµÙˆØ± Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ù€ Selenium Ù…Ù†: {article_url}")
    
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("window-size=1920,1080")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    
    service = ChromeService(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    stealth(driver,
            languages=["en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True)
    
    images_data = []
    
    try:
        print("    â³ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©...")
        driver.get(article_url)
        time.sleep(3)
        
        wait = WebDriverWait(driver, 10)
        
        article_element = None
        selectors = ["article.article", "article", "div.entry-content", "main"]
        for selector in selectors:
            try:
                article_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
                print(f"    âœ“ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙÙŠ: {selector}")
                break
            except: continue
        if not article_element:
            print("    âš ï¸ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŒ Ø³Ø£Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØµÙØ­Ø© ÙƒØ§Ù…Ù„Ø©")
            article_element = driver.find_element(By.TAG_NAME, "body")
        
        for i in range(1, 5):
            driver.execute_script(f"window.scrollTo(0, document.body.scrollHeight*{i}/4);")
            time.sleep(1)

        print("    ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙˆØ±...")
        img_elements = article_element.find_elements(By.TAG_NAME, "img")
        print(f"    ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„: {len(img_elements)}")
        for img in img_elements:
            try:
                src = None
                for attr in ['src', 'data-src', 'data-lazy-src', 'data-original', 'data-srcset']:
                    src = img.get_attribute(attr)
                    if src: break
                if not src: src = driver.execute_script("return arguments[0].currentSrc || arguments[0].src;", img)
                if not src: continue
                if ' ' in src and ',' in src: src = src.split(',')[-1].strip().split(' ')[0]
                
                alt_text = img.get_attribute("alt") or img.get_attribute("title") or ""
                
                if not src.startswith("http"):
                    from urllib.parse import urljoin
                    src = urljoin(article_url, src)

                if is_valid_article_image(src):
                    width = img.get_attribute("width") or driver.execute_script("return arguments[0].naturalWidth;", img)
                    try:
                        if int(width) < 200: continue
                    except: pass
                    if not any(d['url'] == src for d in images_data):
                        images_data.append({'url': src, 'alt': alt_text})
                        print(f"    âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø©: {src[:60]}...")
            except Exception as e:
                print(f"    âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø©: {e}")
        print(f"--- âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(images_data)} ØµÙˆØ±Ø© ØµØ§Ù„Ø­Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„")
    except Exception as e:
        print(f"--- âš ï¸ Ø®Ø·Ø£ ÙÙŠ Selenium: {e}")
    finally:
        driver.quit()
    return images_data

def get_best_images_for_article(article_url, rss_image=None):
    scraped_images_data = scrape_article_images_with_alt(article_url)
    all_images_data = list(scraped_images_data)
    if rss_image and is_valid_article_image(rss_image) and not any(d['url'] == rss_image for d in all_images_data):
        all_images_data.append({'url': rss_image, 'alt': 'Featured recipe image'})
    
    if len(all_images_data) >= 2:
        return all_images_data[0], all_images_data[1]
    elif len(all_images_data) == 1:
        return all_images_data[0], all_images_data[0]
    return None, None

def create_mid_cta(original_link, recipe_title="this recipe"):
    import hashlib
    cta_variations = [
        f'ğŸ’¡ <em>Want to see the exact measurements and timing? Check out <a href="{original_link}" rel="noopener" target="_blank">the full recipe on {SITE_DOMAIN}</a></em>',
        f'ğŸ‘‰ <em>Get all the ingredients and detailed steps for {recipe_title} on <a href="{original_link}" rel="noopener" target="_blank">{SITE_DOMAIN}</a></em>',
    ]
    index = int(hashlib.md5(original_link.encode()).hexdigest(), 16) % len(cta_variations)
    return f'<p>{cta_variations[index]}</p>'

def create_final_cta(original_link):
    return f'''<br><hr><h3>Ready to Make This Recipe?</h3><p><strong>ğŸ¯ Get the complete recipe with exact measurements, step-by-step instructions, and nutritional information.</strong></p><p><strong>ğŸ‘‡ Visit <a href="{original_link}" rel="noopener" target="_blank">{SITE_DOMAIN}</a> for the full recipe!</strong></p>'''

def rewrite_content_with_gemini(title, content_html, original_link, image1_alt="", image2_alt=""):
    if not GEMINI_API_KEY:
        print("!!! ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ GEMINI_API_KEY.")
        return None
    print("--- ğŸ’¬ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Gemini API Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§Ù„ Ø§Ø­ØªØ±Ø§ÙÙŠ...")
    clean_content = re.sub('<[^<]+?>', ' ', content_html)
    alt_info = f"\n- Image 1 description: {image1_alt}" if image1_alt else ""
    if image2_alt and image2_alt != image1_alt: alt_info += f"\n- Image 2 description: {image2_alt}"
    prompt = f"""You are a professional SEO copywriter for Medium. Rewrite a recipe article for maximum engagement.
    **Original Data:**
    - Title: "{title}"
    - Content: "{clean_content[:1500]}"
    - Link: "{original_link}"{alt_info}
    **Requirements:**
    1. **New Title:** Engaging, SEO-optimized title (60-70 characters).
    2. **Article Body:** 600-700 words in clean HTML (p, h2, h3, ul, ol, li, strong, em, br).
       - Compelling intro, practical tips, headers.
       - **IMPORTANT**: Insert these EXACT placeholders: INSERT_IMAGE_1_HERE, INSERT_MID_CTA_HERE, INSERT_IMAGE_2_HERE.
       - NO other links or CTAs.
    3. **Tags:** 5 relevant Medium tags.
    4. **Image Captions:** Engaging captions for the images.
    **Output Format:** Return ONLY a valid JSON object with keys: "new_title", "new_html_content", "tags", "caption1", "caption2".
    """
    api_url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}'
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"maxOutputTokens": 4096, "temperature": 0.7}}
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(data), timeout=180)
        response.raise_for_status()
        raw_text = response.json()['candidates'][0]['content']['parts'][0]['text']
        json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group(0))
            print("--- âœ… ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ù…Ù‚Ø§Ù„ Ù…Ø­Ø³Ù‘Ù† Ù…Ù† Gemini.")
            return {
                "title": result.get("new_title", title),
                "content": result.get("new_html_content", content_html),
                "tags": result.get("tags", []),
                "caption1": result.get("caption1", ""),
                "caption2": result.get("caption2", "")
            }
    except Exception as e:
        print(f"!!! Ø®Ø·Ø£ ÙÙŠ Gemini: {e}")
    return None

def prepare_html_with_multiple_images_and_ctas(content_html, image1_data, image2_data, original_link, original_title, caption1="", caption2=""):
    print("--- ğŸ¨ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù…Ø¹ Ø§Ù„ØµÙˆØ± ÙˆCTAs...")
    image1_html = image2_html = ""
    if image1_data:
        alt1 = image1_data['alt'] or "Recipe preparation"
        cap1 = caption1 or f"{alt1} | {SITE_DOMAIN}"
        image1_html = f'<img src="{image1_data["url"]}" alt="{alt1} | {SITE_DOMAIN}"><p><em>{cap1}</em></p>'
    if image2_data:
        alt2 = image2_data['alt'] or "Final dish"
        cap2 = caption2 or f"{alt2} | {SITE_DOMAIN}"
        image2_html = f'<img src="{image2_data["url"]}" alt="{alt2} | {SITE_DOMAIN}"><p><em>{cap2}</em></p>'
    
    content_html = content_html.replace("INSERT_IMAGE_1_HERE", image1_html)
    content_html = content_html.replace("INSERT_MID_CTA_HERE", create_mid_cta(original_link, original_title))
    content_html = content_html.replace("INSERT_IMAGE_2_HERE", image2_html)
    return content_html + create_final_cta(original_link)

def main():
    print(f"--- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±ÙˆØ¨ÙˆØª Ø§Ù„Ù†Ø§Ø´Ø± v37 Ù„Ù…ÙˆÙ‚Ø¹ {SITE_DOMAIN} ---")
    post_to_publish = get_next_post_to_publish()
    if not post_to_publish:
        print(">>> Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.")
        return

    original_title, original_link = post_to_publish.title, post_to_publish.link
    rss_image = extract_image_url_from_entry(post_to_publish)
    image1_data, image2_data = get_best_images_for_article(original_link, rss_image)
    
    original_content_html = post_to_publish.content[0].value if 'content' in post_to_publish and post_to_publish.content else post_to_publish.summary
    
    rewritten_data = rewrite_content_with_gemini(
        original_title, original_content_html, original_link,
        image1_data['alt'] if image1_data else "", image2_data['alt'] if image2_data else ""
    )
    
    if rewritten_data:
        final_title = rewritten_data["title"]
        full_html_content = prepare_html_with_multiple_images_and_ctas(
            rewritten_data["content"], image1_data, image2_data, original_link, original_title,
            rewritten_data.get("caption1", ""), rewritten_data.get("caption2", "")
        )
        ai_tags = rewritten_data.get("tags", [])
        print("--- âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†.")
    else:
        print("--- âš ï¸ ÙØ´Ù„ GeminiØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ØµÙ„ÙŠ.")
        final_title, ai_tags = original_title, []
        full_html_content = prepare_html_with_multiple_images_and_ctas(
            original_content_html, image1_data, image2_data, original_link, original_title
        )

    sid_cookie, uid_cookie = os.environ.get("MEDIUM_SID_COOKIE"), os.environ.get("MEDIUM_UID_COOKIE")
    if not sid_cookie or not uid_cookie:
        print("!!! Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆÙƒÙŠØ²."); return

    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("window-size=1920,1080")
    service = ChromeService(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    stealth(driver, languages=["en-US", "en"], vendor="Google Inc.", platform="Win32",
            webgl_vendor="Intel Inc.", renderer="Intel Iris OpenGL Engine", fix_hairline=True)
    
    try:
        print("--- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø©...")
        driver.get("https://medium.com/")
        driver.add_cookie({"name": "sid", "value": sid_cookie, "domain": ".medium.com"})
        driver.add_cookie({"name": "uid", "value": uid_cookie, "domain": ".medium.com"})
        
        print("--- 3. Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø­Ø±Ø± Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª...")
        driver.get("https://medium.com/new-story")
        wait = WebDriverWait(driver, 30)
        
        print("--- 4. ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰...")
        wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'h3[data-testid="editorTitleParagraph"]'))).send_keys(final_title)
        story_field = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'p[data-testid="editorParagraphText"]')))
        driver.execute_script("navigator.clipboard.writeText(arguments[0]);", full_html_content)
        story_field.send_keys(Keys.CONTROL, 'v')
        print("--- â³ Ø§Ù†ØªØ¸Ø§Ø± Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±..."); time.sleep(15)
        
        print("--- 6. ÙØªØ­ Ù†Ø§ÙØ°Ø© Ø§Ù„Ù†Ø´Ø±...");
        wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-action="show-prepublish"]'))).click()
        
        print("--- 7. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ³ÙˆÙ…...")
        tags_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid="publishTopicsInput"]')))
        if ai_tags:
            tags_input.click()
            for tag in ai_tags[:5]:
                tags_input.send_keys(tag); time.sleep(0.5); tags_input.send_keys(Keys.ENTER); time.sleep(1)
            print(f"--- ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ³ÙˆÙ…: {', '.join(ai_tags[:5])}")
        else:
            print("--- Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ³ÙˆÙ… Ù„Ø¥Ø¶Ø§ÙØªÙ‡Ø§.")
        
        # === Ø§Ù„Ø­Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø¯Ù…Ø¬ Ù‡Ù†Ø§ ===
        print("    ... Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ù†Ø§ÙØ°Ø© Ø§Ù„Ø­ÙˆØ§Ø± Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ±ÙƒÙŠØ² Ù…Ù† Ø§Ù„ÙˆØ³ÙˆÙ…")
        try:
            dialog_element = driver.find_element(By.CSS_SELECTOR, "div[role='dialog']")
            dialog_element.click()
            time.sleep(1)
        except Exception as e:
            print(f"    âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø­ÙˆØ§Ø± Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ±ÙƒÙŠØ² (Ø³ÙŠØ³ØªÙ…Ø±): {e}")

        print("--- 8. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©...")
        try:
            meter_checkbox = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='checkbox'][id*='meter']")))
            if not meter_checkbox.is_selected():
                print("    âš ï¸ Ø®ÙŠØ§Ø± ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø¯Ø®Ù„ ØºÙŠØ± Ù…Ø­Ø¯Ø¯. Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡ Ø§Ù„Ø¢Ù†.")
                driver.execute_script("arguments[0].click();", meter_checkbox); time.sleep(1)
            else: print("    â„¹ï¸ Ø®ÙŠØ§Ø± ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø¯Ø®Ù„ Ù…Ø­Ø¯Ø¯ Ø¨Ø§Ù„ÙØ¹Ù„.")
        except: print("    â„¹ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®ÙŠØ§Ø± ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø¯Ø®Ù„ (Ø£Ùˆ Ù„ÙŠØ³ Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹).")

        print("--- 9. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù†Ø´Ø± (Ø§Ù„Ù‡Ø¬ÙˆÙ… Ø§Ù„Ø´Ø§Ù…Ù„)...")
        final_publish_button_selector = 'button[data-testid="publishConfirmButton"]'
        final_publish_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, final_publish_button_selector)))
        
        print("    âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ù†Ø´Ø±. Ø¨Ø¯Ø¡ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù†Ù‚Ø± Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")
        actions = ActionChains(driver)
        actions.move_to_element(final_publish_button).pause(0.5).click().perform()
        print("    - ØªÙ…Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù†Ù‚Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ActionChains."); time.sleep(2)

        try:
            button_check = driver.find_element(By.CSS_SELECTOR, final_publish_button_selector)
            print("    âš ï¸ Ø§Ù„Ø²Ø± Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹. Ø§Ù„Ù†Ù‚Ø±Ø© Ù„Ù… ØªÙ†Ø¬Ø­. Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®ÙŠØ±Ø© Ø¨Ù€ JavaScript...")
            driver.execute_script("arguments[0].click();", button_check)
            print("    - ØªÙ…Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø¨Ù€ JavaScript.")
        except:
            print("    âœ… ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø§Ù„Ù†Ù‚Ø±Ø© Ù†Ø¬Ø­Øª ÙˆØ§Ø®ØªÙØª Ø§Ù„Ù†Ø§ÙØ°Ø©.")
        # ======================= Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø­Ù„ =======================
        
        print("--- 10. Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ø´Ø± (20 Ø«Ø§Ù†ÙŠØ©)..."); time.sleep(20)
        
        print("--- 11. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„Ù†Ø´Ø±...")
        final_url = driver.current_url
        print(f"    ğŸ”— Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø´Ø±: {final_url}")
        
        if "/edit" in final_url or "/draft" in final_url:
            driver.save_screenshot("publish_failed_final_page.png")
            raise Exception("Post was not published, it remained a draft.")
        else:
            add_posted_link(original_link)
            print(f">>> ğŸ‰ğŸ‰ğŸ‰ ØªÙ… Ù†Ø´Ø± Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ {SITE_DOMAIN}! ğŸ‰ğŸ‰ğŸ‰")
        
    except Exception as e:
        print(f"!!! Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø´Ø±: {e}")
        driver.save_screenshot("error_screenshot.png")
        with open("error_page_source.html", "w", encoding="utf-8") as f: f.write(driver.page_source)
    finally:
        driver.quit()
        print("--- ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø±ÙˆØ¨ÙˆØª ---")

if __name__ == "__main__":
    main()
